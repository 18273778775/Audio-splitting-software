#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
éŸ³é¢‘åˆ†å‰²å·¥å…·
æ”¯æŒMP3å’ŒWAVæ ¼å¼çš„éŸ³é¢‘æ–‡ä»¶åˆ†å‰²
"""

import os
import sys
import threading
import tkinter as tk
from tkinter import filedialog, messagebox, ttk
from pathlib import Path
import math

try:
    import librosa
    import soundfile as sf
    import numpy as np
    from scipy import signal
    import matplotlib.pyplot as plt
    from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg
    from video_processor import VideoProcessor
except ImportError as e:
    print(f"è¯·å®‰è£…å¿…è¦çš„å¤„ç†åº“:")
    print(f"pip install librosa soundfile numpy scipy matplotlib opencv-python")
    print(f"é”™è¯¯è¯¦æƒ…: {e}")
    sys.exit(1)


class AudioSplitter:
    """éŸ³é¢‘åˆ†å‰²æ ¸å¿ƒç±»"""
    
    def __init__(self):
        self.supported_formats = ['.mp3', '.wav']
        self.video_processor = VideoProcessor()
    
    def is_supported_format(self, file_path):
        """æ£€æŸ¥æ–‡ä»¶æ ¼å¼æ˜¯å¦æ”¯æŒ"""
        return Path(file_path).suffix.lower() in self.supported_formats

    def analyze_audio_volume(self, audio_data, sample_rate, window_size=0.02):
        """
        åˆ†æéŸ³é¢‘çš„éŸ³é‡å˜åŒ–

        Args:
            audio_data: éŸ³é¢‘æ•°æ®
            sample_rate: é‡‡æ ·ç‡
            window_size: åˆ†æçª—å£å¤§å°ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤0.02ç§’æé«˜ç²¾åº¦

        Returns:
            tuple: (æ—¶é—´è½´, RMSéŸ³é‡æ•°ç»„)
        """
        # è®¡ç®—çª—å£å¤§å°ï¼ˆé‡‡æ ·ç‚¹æ•°ï¼‰
        window_samples = int(window_size * sample_rate)

        # è®¡ç®—RMSéŸ³é‡ï¼Œä½¿ç”¨æ›´å°çš„æ­¥é•¿æé«˜ç²¾åº¦
        rms_values = []
        time_points = []

        # ä½¿ç”¨æ›´å°çš„æ­¥é•¿ï¼šçª—å£å¤§å°çš„1/4ï¼Œæé«˜æ—¶é—´ç²¾åº¦
        step_samples = max(1, window_samples // 4)

        for i in range(0, len(audio_data) - window_samples, step_samples):
            window_data = audio_data[i:i + window_samples]
            rms = np.sqrt(np.mean(window_data ** 2))
            rms_values.append(rms)
            # ä½¿ç”¨æ›´ç²¾ç¡®çš„æ—¶é—´è®¡ç®—
            time_points.append(i / sample_rate)

        return np.array(time_points), np.array(rms_values)

    def find_silence_regions(self, audio_data, sample_rate, silence_threshold=0.01, min_silence_duration=0.1):
        """
        æ£€æµ‹éŸ³é¢‘ä¸­çš„é™éŸ³åŒºåŸŸ

        Args:
            audio_data: éŸ³é¢‘æ•°æ®
            sample_rate: é‡‡æ ·ç‡
            silence_threshold: é™éŸ³é˜ˆå€¼ï¼ˆRMSå€¼ï¼‰
            min_silence_duration: æœ€å°é™éŸ³æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰

        Returns:
            list: é™éŸ³åŒºåŸŸåˆ—è¡¨ [(start_time, end_time), ...]
        """
        time_points, rms_values = self.analyze_audio_volume(audio_data, sample_rate)

        # æ‰¾åˆ°ä½äºé˜ˆå€¼çš„åŒºåŸŸ
        silence_mask = rms_values < silence_threshold

        # æ‰¾åˆ°è¿ç»­çš„é™éŸ³åŒºåŸŸ
        silence_regions = []
        in_silence = False
        silence_start = 0

        for i, is_silent in enumerate(silence_mask):
            if is_silent and not in_silence:
                # é™éŸ³å¼€å§‹
                in_silence = True
                silence_start = time_points[i]
            elif not is_silent and in_silence:
                # é™éŸ³ç»“æŸ
                in_silence = False
                silence_end = time_points[i]

                # æ£€æŸ¥é™éŸ³æŒç»­æ—¶é—´
                if silence_end - silence_start >= min_silence_duration:
                    silence_regions.append((silence_start, silence_end))

        # å¤„ç†éŸ³é¢‘ç»“å°¾çš„é™éŸ³
        if in_silence:
            silence_end = time_points[-1] if len(time_points) > 0 else 0
            if silence_end - silence_start >= min_silence_duration:
                silence_regions.append((silence_start, silence_end))

        return silence_regions

    def find_optimal_split_point(self, audio_data, sample_rate, target_time, search_range=2.0):
        """
        åœ¨ç›®æ ‡æ—¶é—´ç‚¹é™„è¿‘å¯»æ‰¾æœ€ä½³åˆ†å‰²ç‚¹

        Args:
            audio_data: éŸ³é¢‘æ•°æ®
            sample_rate: é‡‡æ ·ç‡
            target_time: ç›®æ ‡åˆ†å‰²æ—¶é—´ï¼ˆç§’ï¼‰
            search_range: æœç´¢èŒƒå›´ï¼ˆç§’ï¼‰ï¼Œåœ¨ç›®æ ‡æ—¶é—´å‰åæ­¤èŒƒå›´å†…æœç´¢

        Returns:
            float: æœ€ä½³åˆ†å‰²æ—¶é—´ç‚¹
        """
        # è®¡ç®—æœç´¢èŒƒå›´
        start_time = max(0, target_time - search_range / 2)
        end_time = min(len(audio_data) / sample_rate, target_time + search_range / 2)

        # è·å–æœç´¢èŒƒå›´å†…çš„éŸ³é¢‘æ•°æ®
        start_sample = int(start_time * sample_rate)
        end_sample = int(end_time * sample_rate)
        search_audio = audio_data[start_sample:end_sample]

        if len(search_audio) == 0:
            return target_time

        # åˆ†æè¿™æ®µéŸ³é¢‘çš„éŸ³é‡ï¼Œä½¿ç”¨æ›´é«˜ç²¾åº¦
        time_points, rms_values = self.analyze_audio_volume(search_audio, sample_rate, window_size=0.01)

        if len(rms_values) == 0:
            return target_time

        # æ‰¾åˆ°éŸ³é‡æœ€ä½çš„ç‚¹
        min_volume_idx = np.argmin(rms_values)
        optimal_time = start_time + time_points[min_volume_idx]

        # ç¡®ä¿ç²¾åº¦ï¼šå››èˆäº”å…¥åˆ°æœ€è¿‘çš„é‡‡æ ·ç‚¹
        optimal_sample = round(optimal_time * sample_rate)
        optimal_time = optimal_sample / sample_rate

        return optimal_time
    
    def split_audio(self, file_path, segment_duration=None, custom_durations=None,
                   smart_split=False, search_range=2.0, progress_callback=None):
        """
        åˆ†å‰²éŸ³é¢‘æ–‡ä»¶

        Args:
            file_path (str): éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            segment_duration (int, optional): å›ºå®šåˆ†å‰²æ—¶é•¿ï¼ˆç§’ï¼‰
            custom_durations (list, optional): è‡ªå®šä¹‰é•¿åº¦æ•°ç»„ï¼ˆç§’ï¼‰
            smart_split (bool): æ˜¯å¦å¯ç”¨æ™ºèƒ½åˆ†å‰²
            search_range (float): æ™ºèƒ½åˆ†å‰²æœç´¢èŒƒå›´ï¼ˆç§’ï¼‰
            progress_callback (callable): è¿›åº¦å›è°ƒå‡½æ•°

        Returns:
            tuple: (success, message, output_files)
        """
        try:
            # å‚æ•°éªŒè¯
            if segment_duration is None and custom_durations is None:
                return False, "å¿…é¡»æŒ‡å®šåˆ†å‰²æ—¶é•¿æˆ–è‡ªå®šä¹‰é•¿åº¦æ•°ç»„", []

            if segment_duration is not None and custom_durations is not None:
                return False, "ä¸èƒ½åŒæ—¶æŒ‡å®šå›ºå®šæ—¶é•¿å’Œè‡ªå®šä¹‰é•¿åº¦", []

            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(file_path):
                return False, "æ–‡ä»¶ä¸å­˜åœ¨", []

            # æ£€æŸ¥æ–‡ä»¶æ ¼å¼
            if not self.is_supported_format(file_path):
                return False, "ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼Œä»…æ”¯æŒMP3å’ŒWAVæ ¼å¼", []

            # åŠ è½½éŸ³é¢‘æ–‡ä»¶
            if progress_callback:
                progress_callback(0, "æ­£åœ¨åŠ è½½éŸ³é¢‘æ–‡ä»¶...")

            # ä½¿ç”¨librosaåŠ è½½éŸ³é¢‘æ–‡ä»¶
            audio_data, sample_rate = librosa.load(file_path, sr=None)

            # è®¡ç®—åˆ†å‰²å‚æ•°
            total_duration = len(audio_data) / sample_rate  # ç§’

            # æ ¹æ®åˆ†å‰²æ¨¡å¼å¤„ç†
            if custom_durations is not None:
                # è‡ªå®šä¹‰é•¿åº¦æ¨¡å¼
                return self._split_audio_custom(audio_data, sample_rate, total_duration,
                                              custom_durations, file_path, smart_split, search_range, progress_callback)
            else:
                # å›ºå®šæ—¶é•¿æ¨¡å¼ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
                return self._split_audio_fixed(audio_data, sample_rate, total_duration,
                                             segment_duration, file_path, smart_split, search_range, progress_callback)

        except Exception as e:
            return False, f"åˆ†å‰²è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}", []

    def split_audio_by_video_durations(self, audio_file_path, video_durations,
                                     smart_split=False, search_range=2.0, progress_callback=None):
        """
        æ ¹æ®è§†é¢‘æ—¶é•¿åˆ—è¡¨åˆ†å‰²éŸ³é¢‘

        Args:
            audio_file_path (str): éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            video_durations (list): è§†é¢‘æ—¶é•¿åˆ—è¡¨ï¼ˆç§’ï¼‰
            smart_split (bool): æ˜¯å¦å¯ç”¨æ™ºèƒ½åˆ†å‰²
            search_range (float): æ™ºèƒ½åˆ†å‰²æœç´¢èŒƒå›´ï¼ˆç§’ï¼‰
            progress_callback (callable): è¿›åº¦å›è°ƒå‡½æ•°

        Returns:
            tuple: (success, message, output_files)
        """
        try:
            # éªŒè¯è¾“å…¥
            if not audio_file_path or not os.path.exists(audio_file_path):
                return False, "éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨", []

            if not self.is_supported_format(audio_file_path):
                return False, f"ä¸æ”¯æŒçš„éŸ³é¢‘æ ¼å¼: {Path(audio_file_path).suffix}", []

            if not video_durations or len(video_durations) == 0:
                return False, "è§†é¢‘æ—¶é•¿åˆ—è¡¨ä¸èƒ½ä¸ºç©º", []

            # æ£€æŸ¥æ‰€æœ‰æ—¶é•¿éƒ½æ˜¯æ­£æ•°
            for i, duration in enumerate(video_durations):
                if duration <= 0:
                    return False, f"ç¬¬{i+1}ä¸ªè§†é¢‘æ—¶é•¿å¿…é¡»å¤§äº0ç§’", []

            # ä½¿ç”¨è‡ªå®šä¹‰é•¿åº¦åˆ†å‰²æ¨¡å¼ï¼Œä¼ å…¥è§†é¢‘æ—¶é•¿ä½œä¸ºè‡ªå®šä¹‰æ—¶é•¿
            return self.split_audio(
                audio_file_path,
                custom_durations=video_durations,
                smart_split=smart_split,
                search_range=search_range,
                progress_callback=progress_callback
            )

        except Exception as e:
            return False, f"è§†é¢‘æ—¶é•¿åŒ¹é…åˆ†å‰²è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}", []

    def _split_audio_fixed(self, audio_data, sample_rate, total_duration, segment_duration, file_path, smart_split, search_range, progress_callback):
        """å›ºå®šæ—¶é•¿åˆ†å‰²æ¨¡å¼"""
        if segment_duration >= total_duration:
            return False, "åˆ†å‰²æ—¶é•¿å¤§äºæˆ–ç­‰äºéŸ³é¢‘æ€»æ—¶é•¿", []

        # è®¡ç®—åˆ†å‰²æ•°é‡
        num_segments = math.ceil(total_duration / segment_duration)

        # åˆ›å»ºè¾“å‡ºç›®å½•
        input_path = Path(file_path)
        output_dir = input_path.parent / "output"
        output_dir.mkdir(exist_ok=True)

        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶åå‰ç¼€
        base_name = input_path.stem
        file_extension = input_path.suffix

        output_files = []

        # è®¡ç®—åˆ†å‰²ç‚¹ - æ‰€æœ‰æ¨¡å¼éƒ½ä½¿ç”¨é«˜ç²¾åº¦ç®—æ³•
        split_points = []
        current_position = 0
        split_points.append(current_position)  # èµ·å§‹ç‚¹

        for i in range(1, num_segments):
            target_time = current_position + segment_duration

            if smart_split:
                # æ™ºèƒ½åˆ†å‰²ï¼šå¯»æ‰¾æœ€ä½³åˆ†å‰²ç‚¹
                optimal_time = self.find_optimal_split_point(audio_data, sample_rate, target_time, search_range)
                split_points.append(optimal_time)
                current_position = optimal_time  # æ›´æ–°å½“å‰ä½ç½®ï¼Œç¡®ä¿ä¸‹ä¸€æ®µä»è¿™é‡Œå¼€å§‹
            else:
                # é«˜ç²¾åº¦å›ºå®šåˆ†å‰²ï¼šç¡®ä¿åˆ†å‰²ç‚¹å¯¹é½åˆ°é‡‡æ ·ç‚¹è¾¹ç•Œ
                # ä½¿ç”¨round()ç¡®ä¿ç²¾ç¡®å¯¹é½åˆ°é‡‡æ ·ç‚¹
                target_sample = round(target_time * sample_rate)
                precise_time = target_sample / sample_rate
                split_points.append(precise_time)
                current_position = precise_time  # æ›´æ–°å½“å‰ä½ç½®ï¼Œç¡®ä¿è¿ç»­æ€§

        split_points.append(total_duration)  # æ·»åŠ ç»“æŸç‚¹

        # æ‰§è¡Œåˆ†å‰²
        for i in range(num_segments):
            start_time = split_points[i]
            end_time = split_points[i + 1]

            # ä½¿ç”¨round()æé«˜ç²¾åº¦ï¼Œé¿å…æˆªæ–­è¯¯å·®
            start_sample = round(start_time * sample_rate)
            end_sample = round(end_time * sample_rate)
            end_sample = min(end_sample, len(audio_data))

            # æå–éŸ³é¢‘ç‰‡æ®µ
            segment_data = audio_data[start_sample:end_sample]

            # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
            output_filename = f"{base_name}_part_{i+1:03d}{file_extension}"
            output_path = output_dir / output_filename

            # ä¿å­˜éŸ³é¢‘ç‰‡æ®µ
            sf.write(str(output_path), segment_data, sample_rate)
            output_files.append(str(output_path))

            # æ›´æ–°è¿›åº¦
            if progress_callback:
                progress = int((i + 1) / num_segments * 100)
                split_type = "æ™ºèƒ½" if smart_split else "å›ºå®š"
                progress_callback(progress, f"æ­£åœ¨{split_type}åˆ†å‰²ç¬¬ {i+1}/{num_segments} ä¸ªç‰‡æ®µ...")

        split_type = "æ™ºèƒ½" if smart_split else "å›ºå®š"
        return True, f"{split_type}åˆ†å‰²å®Œæˆï¼å…±ç”Ÿæˆ {num_segments} ä¸ªæ–‡ä»¶", output_files

    def _split_audio_custom(self, audio_data, sample_rate, total_duration, custom_durations, file_path, smart_split, search_range, progress_callback):
        """è‡ªå®šä¹‰é•¿åº¦åˆ†å‰²æ¨¡å¼"""
        # éªŒè¯è‡ªå®šä¹‰é•¿åº¦æ•°ç»„
        if not custom_durations or len(custom_durations) == 0:
            return False, "è‡ªå®šä¹‰é•¿åº¦æ•°ç»„ä¸èƒ½ä¸ºç©º", []

        # æ£€æŸ¥æ‰€æœ‰é•¿åº¦éƒ½æ˜¯æ­£æ•°
        for i, duration in enumerate(custom_durations):
            if duration <= 0:
                return False, f"ç¬¬{i+1}ä¸ªé•¿åº¦å¿…é¡»å¤§äº0ç§’", []

        # è®¡ç®—æŒ‡å®šæ®µçš„æ€»æ—¶é•¿
        specified_total = sum(custom_durations)

        # è®¡ç®—æœ€åä¸€æ®µçš„é•¿åº¦
        last_segment_duration = total_duration - specified_total

        # æ£€æŸ¥è¾¹ç•Œæ¡ä»¶
        if specified_total >= total_duration:
            return False, f"æŒ‡å®šçš„æ€»æ—¶é•¿({specified_total:.1f}ç§’)å¤§äºæˆ–ç­‰äºéŸ³é¢‘æ€»æ—¶é•¿({total_duration:.1f}ç§’)", []

        # ç¡®å®šæ˜¯å¦åˆ›å»ºæœ€åä¸€æ®µ
        create_last_segment = last_segment_duration >= 1.0  # æœ€åä¸€æ®µè‡³å°‘1ç§’

        # è®¡ç®—æ€»æ®µæ•°
        total_segments = len(custom_durations) + (1 if create_last_segment else 0)

        # åˆ›å»ºè¾“å‡ºç›®å½•
        input_path = Path(file_path)
        output_dir = input_path.parent / "output"
        output_dir.mkdir(exist_ok=True)

        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶åå‰ç¼€
        base_name = input_path.stem
        file_extension = input_path.suffix

        output_files = []

        # è®¡ç®—åˆ†å‰²ç‚¹
        split_points = [0]  # èµ·å§‹ç‚¹
        current_position = 0

        for duration in custom_durations:
            target_time = current_position + duration
            if smart_split:
                # æ™ºèƒ½åˆ†å‰²ï¼šå¯»æ‰¾æœ€ä½³åˆ†å‰²ç‚¹
                optimal_time = self.find_optimal_split_point(audio_data, sample_rate, target_time, search_range)
                split_points.append(optimal_time)
                current_position = optimal_time  # æ›´æ–°å½“å‰ä½ç½®ï¼Œç¡®ä¿è¿è´¯æ€§
            else:
                # é«˜ç²¾åº¦å›ºå®šåˆ†å‰²ï¼šç¡®ä¿åˆ†å‰²ç‚¹å¯¹é½åˆ°é‡‡æ ·ç‚¹è¾¹ç•Œ
                # ä½¿ç”¨round()ç¡®ä¿ç²¾ç¡®å¯¹é½åˆ°é‡‡æ ·ç‚¹
                target_sample = round(target_time * sample_rate)
                precise_time = target_sample / sample_rate
                split_points.append(precise_time)
                current_position = precise_time  # æ›´æ–°å½“å‰ä½ç½®ï¼Œç¡®ä¿è¿ç»­æ€§

        # åˆ†å‰²æŒ‡å®šé•¿åº¦çš„æ®µ
        for i, duration in enumerate(custom_durations):
            start_time = split_points[i]
            end_time = split_points[i + 1]

            # ä½¿ç”¨round()æé«˜ç²¾åº¦ï¼Œé¿å…æˆªæ–­è¯¯å·®
            start_sample = round(start_time * sample_rate)
            end_sample = round(end_time * sample_rate)

            # ç¡®ä¿ä¸è¶…å‡ºéŸ³é¢‘èŒƒå›´
            end_sample = min(end_sample, len(audio_data))

            # æå–éŸ³é¢‘ç‰‡æ®µ
            segment_data = audio_data[start_sample:end_sample]

            # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
            output_filename = f"{base_name}_part_{i+1:03d}{file_extension}"
            output_path = output_dir / output_filename

            # ä¿å­˜éŸ³é¢‘ç‰‡æ®µ
            sf.write(str(output_path), segment_data, sample_rate)
            output_files.append(str(output_path))

            # æ›´æ–°è¿›åº¦
            if progress_callback:
                progress = int((i + 1) / total_segments * 100)
                split_type = "æ™ºèƒ½" if smart_split else "è‡ªå®šä¹‰"
                progress_callback(progress, f"æ­£åœ¨{split_type}åˆ†å‰²ç¬¬ {i+1}/{total_segments} ä¸ªç‰‡æ®µ...")

        # å¤„ç†æœ€åä¸€æ®µï¼ˆå¦‚æœéœ€è¦ï¼‰
        if create_last_segment:
            start_time = split_points[-1]
            # ä½¿ç”¨round()æé«˜ç²¾åº¦
            start_sample = round(start_time * sample_rate)
            end_sample = len(audio_data)

            # æå–éŸ³é¢‘ç‰‡æ®µ
            segment_data = audio_data[start_sample:end_sample]

            # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
            segment_index = len(custom_durations) + 1
            output_filename = f"{base_name}_part_{segment_index:03d}{file_extension}"
            output_path = output_dir / output_filename

            # ä¿å­˜éŸ³é¢‘ç‰‡æ®µ
            sf.write(str(output_path), segment_data, sample_rate)
            output_files.append(str(output_path))

            # æ›´æ–°è¿›åº¦
            if progress_callback:
                split_type = "æ™ºèƒ½" if smart_split else "è‡ªå®šä¹‰"
                progress_callback(100, f"æ­£åœ¨{split_type}åˆ†å‰²ç¬¬ {total_segments}/{total_segments} ä¸ªç‰‡æ®µ...")

        # ç”Ÿæˆç»“æœæ¶ˆæ¯
        split_type = "æ™ºèƒ½" if smart_split else "è‡ªå®šä¹‰"
        message = f"{split_type}åˆ†å‰²å®Œæˆï¼å…±ç”Ÿæˆ {len(output_files)} ä¸ªæ–‡ä»¶"
        if not create_last_segment:
            message += f"ï¼ˆæœ€åä¸€æ®µæ—¶é•¿{last_segment_duration:.1f}ç§’ï¼Œå°äº1ç§’ï¼Œå·²è·³è¿‡ï¼‰"

        return True, message, output_files


class WaveformViewer:
    """éŸ³é¢‘æ³¢å½¢å¯è§†åŒ–çª—å£"""

    def __init__(self, parent, audio_file, splitter):
        self.parent = parent
        self.audio_file = audio_file
        self.splitter = splitter
        self.audio_data = None
        self.sample_rate = None
        self.split_points = []
        self.selected_point_index = None
        self.dragging = False

        # åˆ›å»ºæ–°çª—å£
        self.window = tk.Toplevel(parent)
        self.window.title("éŸ³é¢‘æ³¢å½¢å¯è§†åŒ–")
        self.window.geometry("1000x600")
        self.window.resizable(True, True)

        self.setup_ui()
        self.load_and_display_audio()

    def setup_ui(self):
        """è®¾ç½®ç”¨æˆ·ç•Œé¢"""
        # ä¸»æ¡†æ¶
        main_frame = ttk.Frame(self.window, padding="10")
        main_frame.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))

        # é…ç½®ç½‘æ ¼æƒé‡
        self.window.columnconfigure(0, weight=1)
        self.window.rowconfigure(0, weight=1)
        main_frame.columnconfigure(0, weight=1)
        main_frame.rowconfigure(1, weight=1)

        # æ§åˆ¶é¢æ¿
        control_frame = ttk.LabelFrame(main_frame, text="æ³¢å½¢æ§åˆ¶", padding="10")
        control_frame.grid(row=0, column=0, sticky=(tk.W, tk.E), pady=(0, 10))

        # åˆ†å‰²ç‚¹ä¿¡æ¯
        self.info_label = ttk.Label(control_frame, text="åŠ è½½ä¸­...")
        self.info_label.grid(row=0, column=0, sticky=tk.W, pady=(0, 5))

        # æŒ‰é’®
        button_frame = ttk.Frame(control_frame)
        button_frame.grid(row=1, column=0, sticky=tk.W)

        ttk.Button(button_frame, text="åˆ·æ–°æ³¢å½¢", command=self.refresh_waveform).pack(side=tk.LEFT, padx=(0, 10))
        ttk.Button(button_frame, text="æ·»åŠ åˆ†å‰²ç‚¹", command=self.add_split_point).pack(side=tk.LEFT, padx=(0, 10))
        ttk.Button(button_frame, text="åˆ é™¤é€‰ä¸­ç‚¹", command=self.delete_selected_point).pack(side=tk.LEFT, padx=(0, 10))
        ttk.Button(button_frame, text="æ¸…é™¤æ‰€æœ‰ç‚¹", command=self.clear_split_points).pack(side=tk.LEFT, padx=(0, 10))
        ttk.Button(button_frame, text="å…³é—­", command=self.window.destroy).pack(side=tk.LEFT)

        # æ³¢å½¢æ˜¾ç¤ºåŒºåŸŸ
        self.figure = plt.Figure(figsize=(12, 6), dpi=80)
        self.canvas = FigureCanvasTkAgg(self.figure, main_frame)
        self.canvas.get_tk_widget().grid(row=1, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))

        # ç»‘å®šé¼ æ ‡äº‹ä»¶
        self.canvas.mpl_connect('button_press_event', self.on_mouse_press)
        self.canvas.mpl_connect('button_release_event', self.on_mouse_release)
        self.canvas.mpl_connect('motion_notify_event', self.on_mouse_motion)

    def load_and_display_audio(self):
        """åŠ è½½å¹¶æ˜¾ç¤ºéŸ³é¢‘æ³¢å½¢"""
        try:
            # åŠ è½½éŸ³é¢‘æ–‡ä»¶
            self.audio_data, self.sample_rate = librosa.load(self.audio_file, sr=None)
            total_duration = len(self.audio_data) / self.sample_rate

            # æ›´æ–°ä¿¡æ¯
            info_text = f"æ–‡ä»¶: {os.path.basename(self.audio_file)} | æ—¶é•¿: {total_duration:.1f}ç§’ | é‡‡æ ·ç‡: {self.sample_rate}Hz"
            info_text += f" | åˆ†å‰²ç‚¹: {len(self.split_points)}ä¸ª"
            if self.selected_point_index is not None:
                info_text += f" | é€‰ä¸­: ç¬¬{self.selected_point_index + 1}ä¸ªç‚¹"
            info_text += " | æç¤º: ç‚¹å‡»åˆ†å‰²ç‚¹å¯é€‰ä¸­å’Œæ‹–æ‹½"
            self.info_label.config(text=info_text)

            # ç»˜åˆ¶æ³¢å½¢
            self.draw_waveform()

        except Exception as e:
            self.info_label.config(text=f"åŠ è½½å¤±è´¥: {str(e)}")

    def draw_waveform(self):
        """ç»˜åˆ¶éŸ³é¢‘æ³¢å½¢"""
        if self.audio_data is None:
            return

        # æ¸…é™¤ä¹‹å‰çš„å›¾å½¢
        self.figure.clear()

        # åˆ›å»ºå­å›¾
        ax1 = self.figure.add_subplot(2, 1, 1)
        ax2 = self.figure.add_subplot(2, 1, 2)

        # æ—¶é—´è½´
        time_axis = np.linspace(0, len(self.audio_data) / self.sample_rate, len(self.audio_data))

        # ç»˜åˆ¶æ³¢å½¢
        ax1.plot(time_axis, self.audio_data, color='blue', alpha=0.7, linewidth=0.5)
        ax1.set_title('éŸ³é¢‘æ³¢å½¢')
        ax1.set_ylabel('æŒ¯å¹…')
        ax1.grid(True, alpha=0.3)

        # åˆ†æéŸ³é‡å¹¶ç»˜åˆ¶
        time_points, rms_values = self.splitter.analyze_audio_volume(self.audio_data, self.sample_rate)
        ax2.plot(time_points, rms_values, color='red', linewidth=2, label='RMSéŸ³é‡')
        ax2.set_title('éŸ³é‡å˜åŒ–')
        ax2.set_xlabel('æ—¶é—´ (ç§’)')
        ax2.set_ylabel('RMSéŸ³é‡')
        ax2.grid(True, alpha=0.3)
        ax2.legend()

        # æ£€æµ‹å¹¶æ ‡è®°é™éŸ³åŒºåŸŸ
        silence_regions = self.splitter.find_silence_regions(self.audio_data, self.sample_rate)
        for start, end in silence_regions:
            ax1.axvspan(start, end, alpha=0.3, color='yellow', label='é™éŸ³åŒºåŸŸ')
            ax2.axvspan(start, end, alpha=0.3, color='yellow')

        # æ ‡è®°åˆ†å‰²ç‚¹ï¼ˆå¦‚æœæœ‰ï¼‰
        if self.split_points:
            for i, point in enumerate(self.split_points):
                # é€‰ä¸­çš„ç‚¹ç”¨çº¢è‰²ï¼Œå…¶ä»–ç”¨ç»¿è‰²
                color = 'red' if i == self.selected_point_index else 'green'
                linewidth = 3 if i == self.selected_point_index else 2

                ax1.axvline(x=point, color=color, linestyle='--', alpha=0.8, linewidth=linewidth,
                           label=f'åˆ†å‰²ç‚¹{i+1}' if i == 0 else '')
                ax2.axvline(x=point, color=color, linestyle='--', alpha=0.8, linewidth=linewidth)

        # è°ƒæ•´å¸ƒå±€
        self.figure.tight_layout()
        self.canvas.draw()

    def set_split_points(self, split_points):
        """è®¾ç½®åˆ†å‰²ç‚¹å¹¶é‡æ–°ç»˜åˆ¶"""
        self.split_points = split_points
        self.draw_waveform()

    def refresh_waveform(self):
        """åˆ·æ–°æ³¢å½¢æ˜¾ç¤º"""
        self.draw_waveform()

    def on_mouse_press(self, event):
        """é¼ æ ‡æŒ‰ä¸‹äº‹ä»¶"""
        if event.inaxes is None or self.audio_data is None:
            return

        # æ£€æŸ¥æ˜¯å¦ç‚¹å‡»äº†åˆ†å‰²ç‚¹é™„è¿‘
        click_time = event.xdata
        if click_time is None:
            return

        # æŸ¥æ‰¾æœ€è¿‘çš„åˆ†å‰²ç‚¹
        if self.split_points:
            distances = [abs(point - click_time) for point in self.split_points]
            min_distance = min(distances)

            # å¦‚æœç‚¹å‡»è·ç¦»åˆ†å‰²ç‚¹å¾ˆè¿‘ï¼ˆ0.2ç§’å†…ï¼‰ï¼Œé€‰ä¸­è¯¥ç‚¹
            if min_distance < 0.2:
                self.selected_point_index = distances.index(min_distance)
                self.dragging = True
                self.draw_waveform()
                return

        # å¦‚æœæ²¡æœ‰ç‚¹å‡»åˆ†å‰²ç‚¹ï¼Œå–æ¶ˆé€‰æ‹©
        self.selected_point_index = None
        self.draw_waveform()

    def on_mouse_release(self, event):
        """é¼ æ ‡é‡Šæ”¾äº‹ä»¶"""
        self.dragging = False

    def on_mouse_motion(self, event):
        """é¼ æ ‡ç§»åŠ¨äº‹ä»¶"""
        if not self.dragging or self.selected_point_index is None or event.inaxes is None:
            return

        # æ‹–æ‹½åˆ†å‰²ç‚¹
        new_time = event.xdata
        if new_time is not None and 0 <= new_time <= len(self.audio_data) / self.sample_rate:
            self.split_points[self.selected_point_index] = new_time
            self.draw_waveform()

    def add_split_point(self):
        """æ·»åŠ åˆ†å‰²ç‚¹"""
        if self.audio_data is None:
            return

        # åœ¨éŸ³é¢‘ä¸­é—´æ·»åŠ ä¸€ä¸ªåˆ†å‰²ç‚¹
        total_duration = len(self.audio_data) / self.sample_rate
        new_point = total_duration / 2

        # å¦‚æœå·²æœ‰åˆ†å‰²ç‚¹ï¼Œåœ¨å®ƒä»¬ä¹‹é—´æ·»åŠ 
        if self.split_points:
            self.split_points.append(new_point)
            self.split_points.sort()
        else:
            self.split_points = [new_point]

        self.draw_waveform()

    def delete_selected_point(self):
        """åˆ é™¤é€‰ä¸­çš„åˆ†å‰²ç‚¹"""
        if self.selected_point_index is not None and 0 <= self.selected_point_index < len(self.split_points):
            del self.split_points[self.selected_point_index]
            self.selected_point_index = None
            self.draw_waveform()

    def clear_split_points(self):
        """æ¸…é™¤æ‰€æœ‰åˆ†å‰²ç‚¹"""
        self.split_points = []
        self.selected_point_index = None
        self.draw_waveform()


class AudioSplitterGUI:
    """éŸ³é¢‘åˆ†å‰²å·¥å…·GUIç•Œé¢"""
    
    def __init__(self):
        self.root = tk.Tk()
        self.root.title("éŸ³é¢‘åˆ†å‰²å·¥å…· v3.2 - è§†é¢‘æ—¶é•¿åŒ¹é…ç‰ˆ")
        self.root.geometry("1400x900")
        self.root.resizable(True, True)
        self.root.minsize(1200, 700)  # è®¾ç½®æœ€å°çª—å£å¤§å°
        
        # è®¾ç½®çª—å£å›¾æ ‡ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        try:
            self.root.iconbitmap("icon.ico")
        except:
            pass
        
        self.splitter = AudioSplitter()
        self.selected_file = ""
        self.is_splitting = False
        self.video_files = []  # è§†é¢‘æ–‡ä»¶åˆ—è¡¨
        self.video_durations = []  # è§†é¢‘æ—¶é•¿åˆ—è¡¨
        
        self.setup_ui()
        
    def setup_ui(self):
        """è®¾ç½®ç”¨æˆ·ç•Œé¢"""
        # ä¸»æ¡†æ¶ - å·¦å³åˆ†æ å¸ƒå±€
        main_frame = ttk.Frame(self.root, padding="15")
        main_frame.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))

        # é…ç½®ä¸»çª—å£ç½‘æ ¼æƒé‡
        self.root.columnconfigure(0, weight=1)
        self.root.rowconfigure(0, weight=1)
        main_frame.columnconfigure(1, weight=3)  # å³ä¾§æ³¢å½¢åŒºåŸŸæƒé‡æ›´å¤§
        main_frame.rowconfigure(0, weight=1)

        # å·¦ä¾§æ§åˆ¶é¢æ¿
        control_panel = ttk.LabelFrame(main_frame, text="æ§åˆ¶é¢æ¿", padding="15")
        control_panel.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S), padx=(0, 15))

        # å³ä¾§æ³¢å½¢æ˜¾ç¤ºåŒºåŸŸ
        waveform_panel = ttk.LabelFrame(main_frame, text="éŸ³é¢‘æ³¢å½¢å¯è§†åŒ–", padding="15")
        waveform_panel.grid(row=0, column=1, sticky=(tk.W, tk.E, tk.N, tk.S))
        
        # === å·¦ä¾§æ§åˆ¶é¢æ¿å†…å®¹ ===

        # æ–‡ä»¶é€‰æ‹©åŒºåŸŸ
        file_frame = ttk.LabelFrame(control_panel, text="éŸ³é¢‘æ–‡ä»¶é€‰æ‹©", padding="12")
        file_frame.grid(row=0, column=0, sticky=(tk.W, tk.E), pady=(0, 20))
        control_panel.columnconfigure(0, weight=1)
        file_frame.columnconfigure(0, weight=1)

        self.file_path_var = tk.StringVar()
        ttk.Label(file_frame, text="é€‰æ‹©éŸ³é¢‘æ–‡ä»¶:").grid(row=0, column=0, sticky=tk.W, pady=(0, 8))

        file_entry_frame = ttk.Frame(file_frame)
        file_entry_frame.grid(row=1, column=0, sticky=(tk.W, tk.E))
        file_entry_frame.columnconfigure(0, weight=1)
        file_frame.columnconfigure(0, weight=1)

        self.file_entry = ttk.Entry(file_entry_frame, textvariable=self.file_path_var, state="readonly")
        self.file_entry.grid(row=0, column=0, sticky=(tk.W, tk.E), padx=(0, 8))

        ttk.Button(file_entry_frame, text="æµè§ˆ", command=self.select_file, width=12).grid(row=0, column=1)
        
        # åˆ†å‰²è®¾ç½®åŒºåŸŸ
        settings_frame = ttk.LabelFrame(control_panel, text="åˆ†å‰²è®¾ç½®", padding="12")
        settings_frame.grid(row=1, column=0, sticky=(tk.W, tk.E), pady=(0, 20))

        # åˆ†å‰²æ¨¡å¼é€‰æ‹©
        mode_frame = ttk.Frame(settings_frame)
        mode_frame.grid(row=0, column=0, sticky=(tk.W, tk.E), pady=(0, 15))

        ttk.Label(mode_frame, text="åˆ†å‰²æ¨¡å¼:").grid(row=0, column=0, sticky=tk.W, pady=(0, 5))

        self.split_mode_var = tk.StringVar(value="fixed")
        mode_radio_frame = ttk.Frame(mode_frame)
        mode_radio_frame.grid(row=1, column=0, sticky=tk.W)

        self.fixed_radio = ttk.Radiobutton(mode_radio_frame, text="å›ºå®šæ—¶é•¿",
                                         variable=self.split_mode_var, value="fixed",
                                         command=self.on_mode_change)
        self.fixed_radio.grid(row=0, column=0, padx=(0, 20))

        self.custom_radio = ttk.Radiobutton(mode_radio_frame, text="è‡ªå®šä¹‰é•¿åº¦",
                                          variable=self.split_mode_var, value="custom",
                                          command=self.on_mode_change)
        self.custom_radio.grid(row=0, column=1, padx=(0, 20))

        self.video_radio = ttk.Radiobutton(mode_radio_frame, text="è§†é¢‘æ—¶é•¿åŒ¹é…",
                                         variable=self.split_mode_var, value="video",
                                         command=self.on_mode_change)
        self.video_radio.grid(row=0, column=2)

        # å›ºå®šæ—¶é•¿è®¾ç½®
        self.fixed_frame = ttk.Frame(settings_frame)
        self.fixed_frame.grid(row=1, column=0, sticky=(tk.W, tk.E), pady=(0, 10))

        ttk.Label(self.fixed_frame, text="åˆ†å‰²æ—¶é•¿:").grid(row=0, column=0, sticky=tk.W, pady=(0, 5))

        duration_frame = ttk.Frame(self.fixed_frame)
        duration_frame.grid(row=1, column=0, sticky=tk.W)

        self.duration_var = tk.StringVar(value="60")
        self.duration_entry = ttk.Entry(duration_frame, textvariable=self.duration_var, width=10)
        self.duration_entry.grid(row=0, column=0, padx=(0, 10))

        self.time_unit_var = tk.StringVar(value="ç§’")
        time_unit_combo = ttk.Combobox(duration_frame, textvariable=self.time_unit_var,
                                     values=["ç§’", "åˆ†é’Ÿ"], state="readonly", width=8)
        time_unit_combo.grid(row=0, column=1)

        # è‡ªå®šä¹‰é•¿åº¦è®¾ç½®
        self.custom_frame = ttk.Frame(settings_frame)
        self.custom_frame.grid(row=2, column=0, sticky=(tk.W, tk.E), pady=(0, 10))

        ttk.Label(self.custom_frame, text="è‡ªå®šä¹‰é•¿åº¦:").grid(row=0, column=0, sticky=tk.W, pady=(0, 5))

        custom_input_frame = ttk.Frame(self.custom_frame)
        custom_input_frame.grid(row=1, column=0, sticky=(tk.W, tk.E))
        custom_input_frame.columnconfigure(0, weight=1)

        self.custom_durations_var = tk.StringVar()
        self.custom_entry = ttk.Entry(custom_input_frame, textvariable=self.custom_durations_var)
        self.custom_entry.grid(row=0, column=0, sticky=(tk.W, tk.E), padx=(0, 10))
        self.custom_entry.bind('<KeyRelease>', self.on_custom_input_change)

        ttk.Label(custom_input_frame, text="ç§’").grid(row=0, column=1)

        # è¯´æ˜æ–‡æœ¬
        help_text = "è¯·è¾“å…¥æ¯æ®µçš„é•¿åº¦ï¼Œç”¨é€—å·åˆ†éš”ï¼Œå¦‚ï¼š3,5,10"
        self.help_label = ttk.Label(self.custom_frame, text=help_text,
                                   foreground="gray", font=("TkDefaultFont", 8))
        self.help_label.grid(row=2, column=0, sticky=tk.W, pady=(5, 0))

        # é¢„è§ˆä¿¡æ¯
        self.preview_label = ttk.Label(self.custom_frame, text="",
                                     foreground="blue", font=("TkDefaultFont", 8))
        self.preview_label.grid(row=3, column=0, sticky=tk.W, pady=(5, 0))

        # è§†é¢‘æ—¶é•¿åŒ¹é…è®¾ç½®
        self.video_frame = ttk.Frame(settings_frame)
        self.video_frame.grid(row=3, column=0, sticky=(tk.W, tk.E), pady=(0, 10))

        ttk.Label(self.video_frame, text="è§†é¢‘æ–‡ä»¶:").grid(row=0, column=0, sticky=tk.W, pady=(0, 5))

        video_button_frame = ttk.Frame(self.video_frame)
        video_button_frame.grid(row=1, column=0, sticky=(tk.W, tk.E))
        video_button_frame.columnconfigure(0, weight=1)

        self.select_videos_button = ttk.Button(video_button_frame, text="ğŸ“ é€‰æ‹©è§†é¢‘æ–‡ä»¶",
                                             command=self.select_video_files, width=18)
        self.select_videos_button.grid(row=0, column=0, sticky=tk.W, padx=(0, 12))

        self.clear_videos_button = ttk.Button(video_button_frame, text="ğŸ—‘ï¸ æ¸…ç©ºåˆ—è¡¨",
                                            command=self.clear_video_files, width=15)
        self.clear_videos_button.grid(row=0, column=1, sticky=tk.W)

        # è§†é¢‘åˆ—è¡¨æ˜¾ç¤º
        video_list_frame = ttk.Frame(self.video_frame)
        video_list_frame.grid(row=2, column=0, sticky=(tk.W, tk.E), pady=(10, 0))
        video_list_frame.columnconfigure(0, weight=1)

        # åˆ›å»ºTreeviewæ¥æ˜¾ç¤ºè§†é¢‘åˆ—è¡¨
        columns = ('åºå·', 'æ–‡ä»¶å', 'æ—¶é•¿')
        self.video_tree = ttk.Treeview(video_list_frame, columns=columns, show='headings', height=7)

        # è®¾ç½®åˆ—æ ‡é¢˜
        self.video_tree.heading('åºå·', text='åºå·', anchor='center')
        self.video_tree.heading('æ–‡ä»¶å', text='æ–‡ä»¶å', anchor='w')
        self.video_tree.heading('æ—¶é•¿', text='æ—¶é•¿(ç§’)', anchor='center')

        # è®¾ç½®åˆ—å®½å’Œæ ·å¼
        self.video_tree.column('åºå·', width=60, anchor='center', minwidth=50)
        self.video_tree.column('æ–‡ä»¶å', width=220, anchor='w', minwidth=150)
        self.video_tree.column('æ—¶é•¿', width=120, anchor='center', minwidth=80)

        self.video_tree.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))

        # æ·»åŠ æ»šåŠ¨æ¡
        video_scrollbar = ttk.Scrollbar(video_list_frame, orient=tk.VERTICAL, command=self.video_tree.yview)
        video_scrollbar.grid(row=0, column=1, sticky=(tk.N, tk.S))
        self.video_tree.configure(yscrollcommand=video_scrollbar.set)

        # è§†é¢‘åˆ—è¡¨æ“ä½œæŒ‰é’®
        video_ops_frame = ttk.Frame(self.video_frame)
        video_ops_frame.grid(row=3, column=0, sticky=tk.W, pady=(12, 0))

        self.move_up_button = ttk.Button(video_ops_frame, text="â†‘ ä¸Šç§»", command=self.move_video_up, width=10)
        self.move_up_button.grid(row=0, column=0, padx=(0, 8))

        self.move_down_button = ttk.Button(video_ops_frame, text="â†“ ä¸‹ç§»", command=self.move_video_down, width=10)
        self.move_down_button.grid(row=0, column=1, padx=(0, 8))

        self.remove_video_button = ttk.Button(video_ops_frame, text="âœ• åˆ é™¤", command=self.remove_selected_video, width=10)
        self.remove_video_button.grid(row=0, column=2)

        # è§†é¢‘åŒ¹é…ä¿¡æ¯
        self.video_info_label = ttk.Label(self.video_frame, text="",
                                        foreground="blue", font=("TkDefaultFont", 8))
        self.video_info_label.grid(row=4, column=0, sticky=tk.W, pady=(10, 0))

        # æ™ºèƒ½åˆ†å‰²é€‰é¡¹
        smart_split_frame = ttk.LabelFrame(settings_frame, text="æ™ºèƒ½åˆ†å‰²è®¾ç½®", padding="12")
        smart_split_frame.grid(row=4, column=0, sticky=(tk.W, tk.E), pady=(15, 0))
        settings_frame.columnconfigure(0, weight=1)
        smart_split_frame.columnconfigure(0, weight=1)

        self.smart_split_var = tk.BooleanVar(value=False)
        self.smart_split_check = ttk.Checkbutton(smart_split_frame,
                                                text="å¯ç”¨æ™ºèƒ½åˆ†å‰²ï¼ˆåœ¨éŸ³é¢‘ä½è°·å¤„åˆ†å‰²ï¼Œé¿å…å¡é¡¿æ„Ÿï¼‰",
                                                variable=self.smart_split_var,
                                                command=self.on_smart_split_change)
        self.smart_split_check.grid(row=0, column=0, sticky=tk.W, pady=(0, 8))

        # æœç´¢èŒƒå›´è®¾ç½®
        range_frame = ttk.Frame(smart_split_frame)
        range_frame.grid(row=1, column=0, sticky=(tk.W, tk.E))

        ttk.Label(range_frame, text="æœç´¢èŒƒå›´:").grid(row=0, column=0, sticky=tk.W, padx=(20, 5))

        self.search_range_var = tk.StringVar(value="2.0")
        self.search_range_entry = ttk.Entry(range_frame, textvariable=self.search_range_var, width=8)
        self.search_range_entry.grid(row=0, column=1, padx=(0, 5))

        ttk.Label(range_frame, text="ç§’ (å»ºè®®1-5ç§’)").grid(row=0, column=2, sticky=tk.W)

        # æ™ºèƒ½åˆ†å‰²è¯´æ˜
        help_text = "æ™ºèƒ½åˆ†å‰²ä¼šåœ¨ç›®æ ‡æ—¶é—´ç‚¹å‰åæŒ‡å®šèŒƒå›´å†…å¯»æ‰¾éŸ³é‡æœ€ä½çš„ä½ç½®è¿›è¡Œåˆ†å‰²"
        self.smart_help_label = ttk.Label(smart_split_frame, text=help_text,
                                         foreground="gray", font=("TkDefaultFont", 8))
        self.smart_help_label.grid(row=2, column=0, sticky=tk.W, pady=(5, 0))
        
        # æ“ä½œæŒ‰é’®åŒºåŸŸ
        button_frame = ttk.LabelFrame(control_panel, text="æ“ä½œ", padding="12")
        button_frame.grid(row=2, column=0, sticky=(tk.W, tk.E), pady=(0, 20))
        button_frame.columnconfigure(0, weight=1)
        button_frame.columnconfigure(1, weight=1)

        # æŒ‰é’®ç½‘æ ¼å¸ƒå±€
        self.split_button = ttk.Button(button_frame, text="ğŸµ å¼€å§‹åˆ†å‰²", command=self.start_splitting)
        self.split_button.grid(row=0, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=(0, 10))

        self.refresh_waveform_button = ttk.Button(button_frame, text="ğŸ”„ åˆ·æ–°æ³¢å½¢", command=self.refresh_waveform)
        self.refresh_waveform_button.grid(row=1, column=0, sticky=(tk.W, tk.E), padx=(0, 8))

        ttk.Button(button_frame, text="âŒ é€€å‡º", command=self.root.quit).grid(row=1, column=1, sticky=(tk.W, tk.E), padx=(8, 0))

        button_frame.columnconfigure(0, weight=1)
        button_frame.columnconfigure(1, weight=1)
        
        # è¿›åº¦æ˜¾ç¤ºåŒºåŸŸ
        progress_frame = ttk.LabelFrame(control_panel, text="çŠ¶æ€ä¿¡æ¯", padding="12")
        progress_frame.grid(row=3, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        control_panel.rowconfigure(3, weight=1)

        self.progress_var = tk.DoubleVar()
        self.progress_bar = ttk.Progressbar(progress_frame, variable=self.progress_var, maximum=100, style="TProgressbar")
        self.progress_bar.grid(row=0, column=0, sticky=(tk.W, tk.E), pady=(0, 10))

        self.status_var = tk.StringVar(value="ğŸµ è¯·é€‰æ‹©éŸ³é¢‘æ–‡ä»¶å¹¶è®¾ç½®åˆ†å‰²å‚æ•°")
        self.status_label = ttk.Label(progress_frame, textvariable=self.status_var, wraplength=350,
                                    font=("TkDefaultFont", 9), foreground="#2E86AB")
        self.status_label.grid(row=1, column=0, sticky=(tk.W, tk.E))

        progress_frame.columnconfigure(0, weight=1)
        
        # === å³ä¾§æ³¢å½¢æ˜¾ç¤ºåŒºåŸŸ ===

        # æ³¢å½¢ä¿¡æ¯æ ‡ç­¾
        self.waveform_info_var = tk.StringVar(value="è¯·é€‰æ‹©éŸ³é¢‘æ–‡ä»¶ä»¥æ˜¾ç¤ºæ³¢å½¢")
        self.waveform_info_label = ttk.Label(waveform_panel, textvariable=self.waveform_info_var,
                                           font=("TkDefaultFont", 9))
        self.waveform_info_label.grid(row=0, column=0, sticky=tk.W, pady=(0, 10))

        # æ³¢å½¢å›¾åŒºåŸŸ
        self.figure = plt.Figure(figsize=(10, 6), dpi=80)
        self.canvas = FigureCanvasTkAgg(self.figure, waveform_panel)
        self.canvas.get_tk_widget().grid(row=1, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))

        # é…ç½®æ³¢å½¢é¢æ¿ç½‘æ ¼æƒé‡
        waveform_panel.columnconfigure(0, weight=1)
        waveform_panel.rowconfigure(1, weight=1)

        # ç»‘å®šé¼ æ ‡äº‹ä»¶
        self.canvas.mpl_connect('button_press_event', self.on_waveform_click)

        # åˆå§‹åŒ–æ³¢å½¢ç›¸å…³å˜é‡
        self.audio_data = None
        self.sample_rate = None
        self.split_points = []
        self.selected_point_index = None

        # åˆå§‹åŒ–ç•Œé¢çŠ¶æ€
        self.on_mode_change()
        self.draw_empty_waveform()
        
    def select_file(self):
        """é€‰æ‹©éŸ³é¢‘æ–‡ä»¶"""
        file_types = [
            ("éŸ³é¢‘æ–‡ä»¶", "*.mp3 *.wav"),
            ("MP3æ–‡ä»¶", "*.mp3"),
            ("WAVæ–‡ä»¶", "*.wav"),
            ("æ‰€æœ‰æ–‡ä»¶", "*.*")
        ]
        
        filename = filedialog.askopenfilename(
            title="é€‰æ‹©éŸ³é¢‘æ–‡ä»¶",
            filetypes=file_types
        )
        
        if filename:
            self.selected_file = filename
            self.file_path_var.set(filename)
            self.status_var.set(f"âœ… å·²é€‰æ‹©æ–‡ä»¶: {os.path.basename(filename)}")
            # æ›´æ–°è‡ªå®šä¹‰é•¿åº¦é¢„è§ˆ
            self.update_custom_preview()
            # åŠ è½½å¹¶æ˜¾ç¤ºæ³¢å½¢
            self.load_and_display_waveform()
    
    def get_duration_in_seconds(self):
        """è·å–åˆ†å‰²æ—¶é•¿ï¼ˆè½¬æ¢ä¸ºç§’ï¼‰"""
        try:
            duration = float(self.duration_var.get())
            if self.time_unit_var.get() == "åˆ†é’Ÿ":
                duration *= 60
            return duration  # ä¿æŒæµ®ç‚¹æ•°ç²¾åº¦ï¼Œä¸ä½¿ç”¨int()æˆªæ–­
        except ValueError:
            return None

    def on_mode_change(self):
        """åˆ†å‰²æ¨¡å¼åˆ‡æ¢äº‹ä»¶å¤„ç†"""
        mode = self.split_mode_var.get()
        if mode == "fixed":
            # æ˜¾ç¤ºå›ºå®šæ—¶é•¿è®¾ç½®ï¼Œéšè—å…¶ä»–è®¾ç½®
            self.fixed_frame.grid()
            self.custom_frame.grid_remove()
            self.video_frame.grid_remove()
        elif mode == "custom":
            # æ˜¾ç¤ºè‡ªå®šä¹‰é•¿åº¦è®¾ç½®ï¼Œéšè—å…¶ä»–è®¾ç½®
            self.fixed_frame.grid_remove()
            self.custom_frame.grid()
            self.video_frame.grid_remove()
            self.update_custom_preview()
        elif mode == "video":
            # æ˜¾ç¤ºè§†é¢‘æ—¶é•¿åŒ¹é…è®¾ç½®ï¼Œéšè—å…¶ä»–è®¾ç½®
            self.fixed_frame.grid_remove()
            self.custom_frame.grid_remove()
            self.video_frame.grid()
            self.update_video_info()

        # æ›´æ–°æ³¢å½¢åˆ†å‰²ç‚¹
        self.update_waveform_split_points()

    def on_custom_input_change(self, event=None):
        """è‡ªå®šä¹‰é•¿åº¦è¾“å…¥å˜åŒ–äº‹ä»¶å¤„ç†"""
        self.update_custom_preview()
        # æ›´æ–°æ³¢å½¢åˆ†å‰²ç‚¹
        self.update_waveform_split_points()

    def parse_custom_durations(self, input_str):
        """è§£æè‡ªå®šä¹‰é•¿åº¦å­—ç¬¦ä¸²"""
        if not input_str.strip():
            return None, "è¯·è¾“å…¥è‡ªå®šä¹‰é•¿åº¦"

        try:
            # åˆ†å‰²å­—ç¬¦ä¸²å¹¶è½¬æ¢ä¸ºæ•°å­—
            parts = [part.strip() for part in input_str.split(',')]
            durations = []

            for i, part in enumerate(parts):
                if not part:
                    return None, f"ç¬¬{i+1}ä¸ªé•¿åº¦ä¸èƒ½ä¸ºç©º"

                try:
                    duration = float(part)
                    if duration <= 0:
                        return None, f"ç¬¬{i+1}ä¸ªé•¿åº¦å¿…é¡»å¤§äº0"
                    durations.append(duration)
                except ValueError:
                    return None, f"ç¬¬{i+1}ä¸ªé•¿åº¦æ ¼å¼é”™è¯¯: {part}"

            if len(durations) == 0:
                return None, "è‡³å°‘éœ€è¦è¾“å…¥ä¸€ä¸ªé•¿åº¦"

            return durations, None

        except Exception as e:
            return None, f"è§£æé”™è¯¯: {str(e)}"

    def select_video_files(self):
        """é€‰æ‹©è§†é¢‘æ–‡ä»¶"""
        file_types = [
            ("è§†é¢‘æ–‡ä»¶", "*.mp4 *.avi *.mov *.mkv *.wmv *.flv *.webm *.m4v"),
            ("MP4æ–‡ä»¶", "*.mp4"),
            ("AVIæ–‡ä»¶", "*.avi"),
            ("MOVæ–‡ä»¶", "*.mov"),
            ("æ‰€æœ‰æ–‡ä»¶", "*.*")
        ]

        files = filedialog.askopenfilenames(
            title="é€‰æ‹©è§†é¢‘æ–‡ä»¶",
            filetypes=file_types
        )

        if files:
            self.add_video_files(files)

    def add_video_files(self, file_paths):
        """æ·»åŠ è§†é¢‘æ–‡ä»¶åˆ°åˆ—è¡¨"""
        # éªŒè¯æ–‡ä»¶
        valid_files, invalid_files, error_messages = self.splitter.video_processor.validate_video_files(file_paths)

        if invalid_files:
            error_msg = "ä»¥ä¸‹æ–‡ä»¶æ— æ³•æ·»åŠ :\n" + "\n".join(error_messages)
            messagebox.showwarning("æ–‡ä»¶éªŒè¯", error_msg)

        if valid_files:
            # è¯»å–è§†é¢‘æ—¶é•¿
            self.read_video_durations(valid_files)

    def read_video_durations(self, file_paths):
        """è¯»å–è§†é¢‘æ–‡ä»¶æ—¶é•¿"""
        def progress_callback(progress, message):
            # è¿™é‡Œå¯ä»¥æ·»åŠ è¿›åº¦æ˜¾ç¤º
            pass

        try:
            # æ‰¹é‡è¯»å–è§†é¢‘æ—¶é•¿
            results = self.splitter.video_processor.batch_get_video_durations(file_paths, progress_callback)

            # æ·»åŠ åˆ°åˆ—è¡¨
            for result in results:
                if result['success']:
                    self.video_files.append(result['file_path'])
                    self.video_durations.append(result['duration'])

            # æ›´æ–°ç•Œé¢æ˜¾ç¤º
            self.update_video_list_display()
            self.update_video_info()

            if len(results) > 0:
                success_count = sum(1 for r in results if r['success'])
                messagebox.showinfo("è¯»å–å®Œæˆ", f"æˆåŠŸè¯»å– {success_count}/{len(results)} ä¸ªè§†é¢‘æ–‡ä»¶çš„æ—¶é•¿")

        except Exception as e:
            messagebox.showerror("é”™è¯¯", f"è¯»å–è§†é¢‘æ—¶é•¿æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")

    def update_video_list_display(self):
        """æ›´æ–°è§†é¢‘åˆ—è¡¨æ˜¾ç¤º"""
        # æ¸…ç©ºç°æœ‰é¡¹ç›®
        for item in self.video_tree.get_children():
            self.video_tree.delete(item)

        # æ·»åŠ è§†é¢‘æ–‡ä»¶ä¿¡æ¯
        for i, (file_path, duration) in enumerate(zip(self.video_files, self.video_durations)):
            file_name = os.path.basename(file_path)
            duration_str = f"{duration:.3f}"
            self.video_tree.insert('', 'end', values=(i+1, file_name, duration_str))

    def update_video_info(self):
        """æ›´æ–°è§†é¢‘åŒ¹é…ä¿¡æ¯"""
        if not self.video_files:
            self.video_info_label.config(text="ğŸ“¹ è¯·é€‰æ‹©è§†é¢‘æ–‡ä»¶", foreground="#95A5A6")
            return

        total_duration = sum(self.video_durations)
        file_count = len(self.video_files)

        info_text = f"ğŸ“¹ å…± {file_count} ä¸ªè§†é¢‘æ–‡ä»¶ï¼Œæ€»æ—¶é•¿: {total_duration:.3f}ç§’"
        self.video_info_label.config(text=info_text, foreground="#2E86AB")

    def clear_video_files(self):
        """æ¸…ç©ºè§†é¢‘æ–‡ä»¶åˆ—è¡¨"""
        self.video_files.clear()
        self.video_durations.clear()
        self.update_video_list_display()
        self.update_video_info()
        self.update_waveform_split_points()

    def move_video_up(self):
        """ä¸Šç§»é€‰ä¸­çš„è§†é¢‘"""
        selection = self.video_tree.selection()
        if not selection:
            return

        item = selection[0]
        index = self.video_tree.index(item)

        if index > 0:
            # äº¤æ¢åˆ—è¡¨ä¸­çš„ä½ç½®
            self.video_files[index], self.video_files[index-1] = self.video_files[index-1], self.video_files[index]
            self.video_durations[index], self.video_durations[index-1] = self.video_durations[index-1], self.video_durations[index]

            # æ›´æ–°æ˜¾ç¤º
            self.update_video_list_display()

            # é‡æ–°é€‰ä¸­ç§»åŠ¨åçš„é¡¹ç›®
            new_item = self.video_tree.get_children()[index-1]
            self.video_tree.selection_set(new_item)

            # æ›´æ–°åˆ†å‰²ç‚¹
            self.update_waveform_split_points()

    def move_video_down(self):
        """ä¸‹ç§»é€‰ä¸­çš„è§†é¢‘"""
        selection = self.video_tree.selection()
        if not selection:
            return

        item = selection[0]
        index = self.video_tree.index(item)

        if index < len(self.video_files) - 1:
            # äº¤æ¢åˆ—è¡¨ä¸­çš„ä½ç½®
            self.video_files[index], self.video_files[index+1] = self.video_files[index+1], self.video_files[index]
            self.video_durations[index], self.video_durations[index+1] = self.video_durations[index+1], self.video_durations[index]

            # æ›´æ–°æ˜¾ç¤º
            self.update_video_list_display()

            # é‡æ–°é€‰ä¸­ç§»åŠ¨åçš„é¡¹ç›®
            new_item = self.video_tree.get_children()[index+1]
            self.video_tree.selection_set(new_item)

            # æ›´æ–°åˆ†å‰²ç‚¹
            self.update_waveform_split_points()

    def remove_selected_video(self):
        """åˆ é™¤é€‰ä¸­çš„è§†é¢‘"""
        selection = self.video_tree.selection()
        if not selection:
            return

        item = selection[0]
        index = self.video_tree.index(item)

        # ä»åˆ—è¡¨ä¸­åˆ é™¤
        del self.video_files[index]
        del self.video_durations[index]

        # æ›´æ–°æ˜¾ç¤º
        self.update_video_list_display()
        self.update_video_info()
        self.update_waveform_split_points()

    def update_custom_preview(self):
        """æ›´æ–°è‡ªå®šä¹‰é•¿åº¦é¢„è§ˆä¿¡æ¯"""
        if self.split_mode_var.get() != "custom":
            return

        input_str = self.custom_durations_var.get()
        durations, error = self.parse_custom_durations(input_str)

        if error:
            self.preview_label.config(text=f"âŒ {error}", foreground="#E74C3C")
            return

        if not durations:
            self.preview_label.config(text="", foreground="blue")
            return

        # è®¡ç®—æ€»æ—¶é•¿
        total_specified = sum(durations)

        # å¦‚æœæœ‰é€‰æ‹©çš„æ–‡ä»¶ï¼Œè®¡ç®—æœ€åä¸€æ®µé•¿åº¦
        if self.selected_file:
            try:
                # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”ç”¨ä¸­å¯èƒ½éœ€è¦ç¼“å­˜éŸ³é¢‘æ—¶é•¿
                import librosa
                audio_data, sample_rate = librosa.load(self.selected_file, sr=None)
                total_duration = len(audio_data) / sample_rate

                last_segment = total_duration - total_specified

                if total_specified >= total_duration:
                    self.preview_label.config(
                        text=f"âŒ æŒ‡å®šæ€»æ—¶é•¿({total_specified:.1f}ç§’)è¶…å‡ºéŸ³é¢‘æ—¶é•¿({total_duration:.1f}ç§’)",
                        foreground="#E74C3C"
                    )
                elif last_segment < 1.0:
                    self.preview_label.config(
                        text=f"âš ï¸ å°†ç”Ÿæˆ{len(durations)}æ®µï¼Œæœ€åä¸€æ®µ({last_segment:.1f}ç§’)å°†è¢«è·³è¿‡",
                        foreground="#F39C12"
                    )
                else:
                    self.preview_label.config(
                        text=f"âœ… å°†ç”Ÿæˆ{len(durations)+1}æ®µï¼Œæœ€åä¸€æ®µ{last_segment:.1f}ç§’",
                        foreground="#27AE60"
                    )
            except:
                self.preview_label.config(
                    text=f"â„¹ï¸ æŒ‡å®š{len(durations)}æ®µï¼Œæ€»æ—¶é•¿{total_specified:.1f}ç§’",
                    foreground="#2E86AB"
                )
        else:
            self.preview_label.config(
                text=f"â„¹ï¸ æŒ‡å®š{len(durations)}æ®µï¼Œæ€»æ—¶é•¿{total_specified:.1f}ç§’",
                foreground="#2E86AB"
            )

    def on_smart_split_change(self):
        """æ™ºèƒ½åˆ†å‰²é€‰é¡¹å˜åŒ–äº‹ä»¶"""
        # å½“æ™ºèƒ½åˆ†å‰²é€‰é¡¹å˜åŒ–æ—¶ï¼Œé‡æ–°è®¡ç®—å’Œæ˜¾ç¤ºåˆ†å‰²ç‚¹
        if self.audio_data is not None:
            self.update_waveform_split_points()

    def get_search_range(self):
        """è·å–æœç´¢èŒƒå›´è®¾ç½®"""
        try:
            range_value = float(self.search_range_var.get())
            return max(0.5, min(5.0, range_value))  # é™åˆ¶åœ¨0.5-5ç§’ä¹‹é—´
        except ValueError:
            return 2.0  # é»˜è®¤å€¼

    def draw_empty_waveform(self):
        """ç»˜åˆ¶ç©ºçš„æ³¢å½¢å›¾"""
        self.figure.clear()
        ax = self.figure.add_subplot(1, 1, 1)
        ax.text(0.5, 0.5, 'è¯·é€‰æ‹©éŸ³é¢‘æ–‡ä»¶ä»¥æ˜¾ç¤ºæ³¢å½¢',
                horizontalalignment='center', verticalalignment='center',
                transform=ax.transAxes, fontsize=14, color='gray')
        ax.set_xlim(0, 1)
        ax.set_ylim(0, 1)
        ax.axis('off')
        self.canvas.draw()

    def load_and_display_waveform(self):
        """åŠ è½½å¹¶æ˜¾ç¤ºéŸ³é¢‘æ³¢å½¢"""
        if not self.selected_file:
            return

        try:
            # åŠ è½½éŸ³é¢‘æ–‡ä»¶
            self.audio_data, self.sample_rate = librosa.load(self.selected_file, sr=None)
            total_duration = len(self.audio_data) / self.sample_rate

            # æ›´æ–°ä¿¡æ¯
            info_text = f"æ–‡ä»¶: {os.path.basename(self.selected_file)} | "
            info_text += f"æ—¶é•¿: {total_duration:.1f}ç§’ | é‡‡æ ·ç‡: {self.sample_rate}Hz"
            self.waveform_info_var.set(info_text)

            # ç»˜åˆ¶æ³¢å½¢
            self.draw_waveform()

        except Exception as e:
            self.waveform_info_var.set(f"åŠ è½½å¤±è´¥: {str(e)}")
            self.draw_empty_waveform()

    def draw_waveform(self):
        """ç»˜åˆ¶éŸ³é¢‘æ³¢å½¢"""
        if self.audio_data is None:
            self.draw_empty_waveform()
            return

        # æ¸…é™¤ä¹‹å‰çš„å›¾å½¢
        self.figure.clear()

        # åˆ›å»ºå­å›¾
        ax1 = self.figure.add_subplot(2, 1, 1)
        ax2 = self.figure.add_subplot(2, 1, 2)

        # æ—¶é—´è½´
        time_axis = np.linspace(0, len(self.audio_data) / self.sample_rate, len(self.audio_data))

        # ç»˜åˆ¶æ³¢å½¢ï¼ˆé‡‡æ ·æ˜¾ç¤ºä»¥æé«˜æ€§èƒ½ï¼‰
        step = max(1, len(self.audio_data) // 10000)  # æœ€å¤šæ˜¾ç¤º10000ä¸ªç‚¹
        ax1.plot(time_axis[::step], self.audio_data[::step], color='#2E86AB', alpha=0.8, linewidth=0.6)
        ax1.set_title('ğŸµ éŸ³é¢‘æ³¢å½¢', fontsize=12, fontweight='bold', color='#2E86AB')
        ax1.set_ylabel('æŒ¯å¹…', fontsize=10)
        ax1.grid(True, alpha=0.3, linestyle='-', linewidth=0.5)
        ax1.set_facecolor('#F8F9FA')

        # åˆ†æéŸ³é‡å¹¶ç»˜åˆ¶
        time_points, rms_values = self.splitter.analyze_audio_volume(self.audio_data, self.sample_rate)
        ax2.plot(time_points, rms_values, color='#E74C3C', linewidth=2.5, label='RMSéŸ³é‡', alpha=0.9)
        ax2.set_title('ğŸ“Š éŸ³é‡å˜åŒ–', fontsize=12, fontweight='bold', color='#E74C3C')
        ax2.set_xlabel('æ—¶é—´ (ç§’)', fontsize=10)
        ax2.set_ylabel('RMSéŸ³é‡', fontsize=10)
        ax2.grid(True, alpha=0.3, linestyle='-', linewidth=0.5)
        ax2.set_facecolor('#F8F9FA')
        ax2.legend(loc='upper right')

        # æ£€æµ‹å¹¶æ ‡è®°é™éŸ³åŒºåŸŸ
        silence_regions = self.splitter.find_silence_regions(self.audio_data, self.sample_rate)
        for start, end in silence_regions:
            ax1.axvspan(start, end, alpha=0.2, color='#F39C12', label='ğŸ”‡ é™éŸ³åŒºåŸŸ' if start == silence_regions[0][0] else '')
            ax2.axvspan(start, end, alpha=0.2, color='#F39C12')

        # æ ‡è®°åˆ†å‰²ç‚¹
        self.draw_split_points(ax1, ax2)

        # è°ƒæ•´å¸ƒå±€
        self.figure.tight_layout()
        self.canvas.draw()

    def draw_split_points(self, ax1, ax2):
        """åœ¨æ³¢å½¢å›¾ä¸Šç»˜åˆ¶åˆ†å‰²ç‚¹"""
        if not self.split_points:
            return

        for i, point in enumerate(self.split_points):
            # é€‰ä¸­çš„ç‚¹ç”¨çº¢è‰²ï¼Œå…¶ä»–ç”¨ç»¿è‰²
            color = '#E74C3C' if i == self.selected_point_index else '#27AE60'
            linewidth = 3.5 if i == self.selected_point_index else 2.5
            alpha = 0.9 if i == self.selected_point_index else 0.7

            ax1.axvline(x=point, color=color, linestyle='--', alpha=alpha, linewidth=linewidth,
                       label=f'âœ‚ï¸ åˆ†å‰²ç‚¹' if i == 0 else '')
            ax2.axvline(x=point, color=color, linestyle='--', alpha=alpha, linewidth=linewidth)

    def update_waveform_split_points(self):
        """æ ¹æ®å½“å‰è®¾ç½®æ›´æ–°æ³¢å½¢ä¸Šçš„åˆ†å‰²ç‚¹"""
        if self.audio_data is None:
            return

        mode = self.split_mode_var.get()
        smart_split = self.smart_split_var.get()
        search_range = self.get_search_range()

        self.split_points = []

        try:
            if mode == "fixed":
                duration = self.get_duration_in_seconds()
                if duration and duration > 0:
                    # è®¡ç®—å›ºå®šæ—¶é•¿åˆ†å‰²ç‚¹
                    total_duration = len(self.audio_data) / self.sample_rate
                    num_segments = math.ceil(total_duration / duration)

                    if smart_split:
                        # æ™ºèƒ½åˆ†å‰²ç‚¹
                        current_position = 0
                        self.split_points.append(current_position)

                        for i in range(1, num_segments):
                            target_time = current_position + duration
                            optimal_time = self.splitter.find_optimal_split_point(
                                self.audio_data, self.sample_rate, target_time, search_range)
                            self.split_points.append(optimal_time)
                            current_position = optimal_time
                    else:
                        # é«˜ç²¾åº¦å›ºå®šåˆ†å‰²ç‚¹
                        for i in range(1, num_segments):
                            target_time = current_position + duration
                            # ä½¿ç”¨round()ç¡®ä¿ç²¾ç¡®å¯¹é½åˆ°é‡‡æ ·ç‚¹
                            target_sample = round(target_time * self.sample_rate)
                            precise_time = target_sample / self.sample_rate
                            self.split_points.append(min(precise_time, total_duration))
                            current_position = precise_time

            elif mode == "custom":
                durations, error = self.parse_custom_durations(self.custom_durations_var.get())
                if durations and not error:
                    # è®¡ç®—è‡ªå®šä¹‰é•¿åº¦åˆ†å‰²ç‚¹
                    current_position = 0
                    self.split_points.append(current_position)

                    for duration in durations:
                        target_time = current_position + duration
                        if smart_split:
                            optimal_time = self.splitter.find_optimal_split_point(
                                self.audio_data, self.sample_rate, target_time, search_range)
                            self.split_points.append(optimal_time)
                            current_position = optimal_time
                        else:
                            # é«˜ç²¾åº¦å›ºå®šåˆ†å‰²ï¼šç¡®ä¿åˆ†å‰²ç‚¹å¯¹é½åˆ°é‡‡æ ·ç‚¹è¾¹ç•Œ
                            target_sample = round(target_time * self.sample_rate)
                            precise_time = target_sample / self.sample_rate
                            self.split_points.append(precise_time)
                            current_position = precise_time

            elif mode == "video":
                if self.video_durations:
                    # è®¡ç®—è§†é¢‘æ—¶é•¿åŒ¹é…åˆ†å‰²ç‚¹
                    current_position = 0
                    self.split_points.append(current_position)

                    for duration in self.video_durations:
                        target_time = current_position + duration
                        if smart_split:
                            optimal_time = self.splitter.find_optimal_split_point(
                                self.audio_data, self.sample_rate, target_time, search_range)
                            self.split_points.append(optimal_time)
                            current_position = optimal_time
                        else:
                            # é«˜ç²¾åº¦å›ºå®šåˆ†å‰²ï¼šç¡®ä¿åˆ†å‰²ç‚¹å¯¹é½åˆ°é‡‡æ ·ç‚¹è¾¹ç•Œ
                            target_sample = round(target_time * self.sample_rate)
                            precise_time = target_sample / self.sample_rate
                            self.split_points.append(precise_time)
                            current_position = precise_time

            # é‡æ–°ç»˜åˆ¶æ³¢å½¢
            self.draw_waveform()

        except Exception as e:
            print(f"æ›´æ–°åˆ†å‰²ç‚¹æ—¶å‘ç”Ÿé”™è¯¯: {e}")

    def on_waveform_click(self, event):
        """æ³¢å½¢å›¾ç‚¹å‡»äº‹ä»¶"""
        if event.inaxes is None or self.audio_data is None:
            return

        click_time = event.xdata
        if click_time is None:
            return

        # æŸ¥æ‰¾æœ€è¿‘çš„åˆ†å‰²ç‚¹
        if self.split_points:
            distances = [abs(point - click_time) for point in self.split_points]
            min_distance = min(distances)

            # å¦‚æœç‚¹å‡»è·ç¦»åˆ†å‰²ç‚¹å¾ˆè¿‘ï¼ˆ0.3ç§’å†…ï¼‰ï¼Œé€‰ä¸­è¯¥ç‚¹
            if min_distance < 0.3:
                self.selected_point_index = distances.index(min_distance)
                self.draw_waveform()
                return

        # å¦‚æœæ²¡æœ‰ç‚¹å‡»åˆ†å‰²ç‚¹ï¼Œå–æ¶ˆé€‰æ‹©
        self.selected_point_index = None
        self.draw_waveform()

    def refresh_waveform(self):
        """åˆ·æ–°æ³¢å½¢æ˜¾ç¤º"""
        if self.selected_file:
            self.load_and_display_waveform()
            self.update_waveform_split_points()
        else:
            self.draw_empty_waveform()


    
    def update_progress(self, progress, message):
        """æ›´æ–°è¿›åº¦æ˜¾ç¤º"""
        self.progress_var.set(progress)
        self.status_var.set(message)
        self.root.update_idletasks()
    
    def start_splitting(self):
        """å¼€å§‹åˆ†å‰²éŸ³é¢‘"""
        if self.is_splitting:
            return

        # éªŒè¯è¾“å…¥
        if not self.selected_file:
            messagebox.showerror("é”™è¯¯", "è¯·å…ˆé€‰æ‹©éŸ³é¢‘æ–‡ä»¶")
            return

        mode = self.split_mode_var.get()
        smart_split = self.smart_split_var.get()
        search_range = self.get_search_range()

        if mode == "fixed":
            # å›ºå®šæ—¶é•¿æ¨¡å¼
            duration = self.get_duration_in_seconds()
            if duration is None or duration <= 0:
                messagebox.showerror("é”™è¯¯", "è¯·è¾“å…¥æœ‰æ•ˆçš„åˆ†å‰²æ—¶é•¿")
                return

            # ç¦ç”¨åˆ†å‰²æŒ‰é’®
            self.is_splitting = True
            self.split_button.config(state="disabled")

            # åœ¨æ–°çº¿ç¨‹ä¸­æ‰§è¡Œåˆ†å‰²æ“ä½œ
            thread = threading.Thread(target=self.split_audio_thread, args=(duration, None, smart_split, search_range))
            thread.daemon = True
            thread.start()

        elif mode == "custom":
            # è‡ªå®šä¹‰é•¿åº¦æ¨¡å¼
            durations, error = self.parse_custom_durations(self.custom_durations_var.get())
            if error:
                messagebox.showerror("é”™è¯¯", error)
                return

            if not durations:
                messagebox.showerror("é”™è¯¯", "è¯·è¾“å…¥æœ‰æ•ˆçš„è‡ªå®šä¹‰é•¿åº¦")
                return

            # ç¦ç”¨åˆ†å‰²æŒ‰é’®
            self.is_splitting = True
            self.split_button.config(state="disabled")

            # åœ¨æ–°çº¿ç¨‹ä¸­æ‰§è¡Œåˆ†å‰²æ“ä½œ
            thread = threading.Thread(target=self.split_audio_thread, args=(None, durations, smart_split, search_range))
            thread.daemon = True
            thread.start()

        elif mode == "video":
            # è§†é¢‘æ—¶é•¿åŒ¹é…æ¨¡å¼
            if not self.video_durations:
                messagebox.showerror("é”™è¯¯", "è¯·å…ˆé€‰æ‹©è§†é¢‘æ–‡ä»¶")
                return

            # ç¦ç”¨åˆ†å‰²æŒ‰é’®
            self.is_splitting = True
            self.split_button.config(state="disabled")

            # åœ¨æ–°çº¿ç¨‹ä¸­æ‰§è¡Œåˆ†å‰²æ“ä½œ
            thread = threading.Thread(target=self.split_audio_thread, args=(None, self.video_durations, smart_split, search_range))
            thread.daemon = True
            thread.start()
    
    def split_audio_thread(self, duration, custom_durations, smart_split, search_range):
        """åœ¨åå°çº¿ç¨‹ä¸­æ‰§è¡ŒéŸ³é¢‘åˆ†å‰²"""
        try:
            success, message, output_files = self.splitter.split_audio(
                self.selected_file,
                segment_duration=duration,
                custom_durations=custom_durations,
                smart_split=smart_split,
                search_range=search_range,
                progress_callback=self.update_progress
            )

            # åœ¨ä¸»çº¿ç¨‹ä¸­æ˜¾ç¤ºç»“æœ
            self.root.after(0, self.show_result, success, message, output_files)

        except Exception as e:
            self.root.after(0, self.show_result, False, f"åˆ†å‰²è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}", [])
    
    def show_result(self, success, message, output_files):
        """æ˜¾ç¤ºåˆ†å‰²ç»“æœ"""
        self.is_splitting = False
        self.split_button.config(state="normal")
        
        if success:
            self.progress_var.set(100)
            self.status_var.set(message)
            messagebox.showinfo("æˆåŠŸ", f"{message}\n\nè¾“å‡ºç›®å½•: {os.path.dirname(output_files[0]) if output_files else ''}")
        else:
            self.progress_var.set(0)
            self.status_var.set(f"åˆ†å‰²å¤±è´¥: {message}")
            messagebox.showerror("é”™è¯¯", message)
    
    def run(self):
        """è¿è¡ŒGUIåº”ç”¨"""
        self.root.mainloop()


def main():
    """ä¸»å‡½æ•°"""
    app = AudioSplitterGUI()
    app.run()


if __name__ == "__main__":
    main()
